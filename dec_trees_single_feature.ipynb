{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to GitHub\n",
    "If running on Google Colab, the following will connect to GitHub and clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_username = ''\n",
    "git_token =  ''\n",
    "\n",
    "if git_username == '':\n",
    "  print('Github username:')\n",
    "  git_username = %sx read -p ''\n",
    "  git_username = git_username[0]\n",
    "\n",
    "if git_token == '':\n",
    "  print('Github access token (https://github.com/settings/tokens):')\n",
    "  print('Github Token:')\n",
    "  git_token = %sx read -p ''\n",
    "  git_token = git_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the entire repo.\n",
    "%cd /content\n",
    "!git clone -l -s https://$git_username:$git_token@github.com/lougau92/MA1-Development-of-XAI-based-framework-to-Understand-Predict-and-Link-Homicides.git research-project\n",
    "%cd machine-learning-and-reasoning\n",
    "!ls\n",
    "!git init\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the entire repo.\n",
    "%cd /content\n",
    "%cd machine-learning-and-reasoning\n",
    "!git pull\n",
    "!ls\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict \n",
    "from sklearn.metrics import confusion_matrix, make_scorer, classification_report, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV, StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from typing import List\n",
    "from preprocess import clean_dataframe, split_stratify, bin_age\n",
    "\n",
    "random_state = 1\n",
    "input_features = ['County', 'State', 'Area', 'VicAge', 'VicSex', 'VicRace', 'VicEthnic', 'VicCount', 'Weapon', 'Subcircum', 'Agency', 'Agentype', 'Circumstance', 'Homicide']\n",
    "output_features = ['OffAge', 'OffSex', 'OffRace', 'OffEthnic', 'OffCount']\n",
    "non_numeric_inputs = ['County', 'State', 'Area', 'VicSex', 'VicRace', 'VicEthnic', 'Weapon', 'Subcircum', 'Agency', 'Agentype', 'Circumstance', 'Homicide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('Murder_Data.zip', index_col=0, compression='zip')\n",
    "cleaned_data = clean_dataframe(raw_data)\n",
    "cleaned_data['VicAge'].replace(to_replace='Unknown', value = 999, inplace = True)\n",
    "cleaned_data['OffAge'] = bin_age(cleaned_data, 'OffAge')\n",
    "cleaned_data['OffAge'] = cleaned_data['OffAge'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(data: pd.DataFrame, non_numeric_features: List[str]):\n",
    "    df = data.copy()\n",
    "    encoder = OrdinalEncoder()\n",
    "    encoder.fit(df[non_numeric_features])\n",
    "    df[non_numeric_features] = encoder.transform(df[non_numeric_features])    \n",
    "    return df, encoder\n",
    "\n",
    "numeric_data, ordinal_encoder = to_numeric(cleaned_data, ['County', 'State', 'Area', 'VicSex', 'VicRace', 'VicEthnic', 'Weapon', 'Subcircum', 'Agency', 'Agentype', 'Circumstance', 'Homicide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample, test_sample = split_stratify(cleaned_data, ['OffAge', 'OffSex', 'OffRace', 'OffEthnic'], 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of          Area  County FileMonth FileDay FileYear  State  Agency  Agentype  \\\n",
      "0         NaN     NaN         3      22       85    NaN     NaN       NaN   \n",
      "1         NaN     NaN         3      22       85    NaN     NaN       NaN   \n",
      "2         NaN     NaN         3      22       85    NaN     NaN       NaN   \n",
      "3         NaN     NaN        10      26       93    NaN     NaN       NaN   \n",
      "4         NaN     NaN        10      26       93    NaN     NaN       NaN   \n",
      "...       ...     ...       ...     ...      ...    ...     ...       ...   \n",
      "1711516   NaN     NaN         U      nk       no    NaN     NaN       NaN   \n",
      "1711517   NaN     NaN         U      nk       no    NaN     NaN       NaN   \n",
      "1711518   NaN     NaN         U      nk       no    NaN     NaN       NaN   \n",
      "1711519   NaN     NaN         U      nk       no    NaN     NaN       NaN   \n",
      "1711520   NaN     NaN         U      nk       no    NaN     NaN       NaN   \n",
      "\n",
      "        Source Solved  ...  OffAge  OffSex OffRace  OffEthnic Weapon  \\\n",
      "0          FBI    Yes  ...     0-2  Female   Black    Unknown    NaN   \n",
      "1          FBI    Yes  ...     0-2  Female   Black    Unknown    NaN   \n",
      "2          FBI    Yes  ...     0-2  Female   Black    Unknown    NaN   \n",
      "3          FBI    Yes  ...     0-2  Female   White    Unknown    NaN   \n",
      "4          FBI    Yes  ...     0-2  Female   White    Unknown    NaN   \n",
      "...        ...    ...  ...     ...     ...     ...        ...    ...   \n",
      "1711516    MAP    Yes  ...     nan    Male   White    Unknown    NaN   \n",
      "1711517    MAP    Yes  ...     nan    Male   White    Unknown    NaN   \n",
      "1711518    MAP    Yes  ...     nan    Male   White    Unknown    NaN   \n",
      "1711519    MAP    Yes  ...     nan    Male   White    Unknown    NaN   \n",
      "1711520    MAP    Yes  ...     nan    Male   White    Unknown    NaN   \n",
      "\n",
      "         Relationship  Circumstance  Subcircum VicCount OffCount  \n",
      "0        Acquaintance           NaN        NaN        0        0  \n",
      "1        Acquaintance           NaN        NaN        0        0  \n",
      "2        Acquaintance           NaN        NaN        0        0  \n",
      "3            Daughter           NaN        NaN        0        0  \n",
      "4            Daughter           NaN        NaN        0        0  \n",
      "...               ...           ...        ...      ...      ...  \n",
      "1711516       Unknown           NaN        NaN        4        0  \n",
      "1711517       Unknown           NaN        NaN        1        0  \n",
      "1711518  Other family           NaN        NaN        1        0  \n",
      "1711519           Son           NaN        NaN        1        0  \n",
      "1711520       Unknown           NaN        NaN        0        0  \n",
      "\n",
      "[1711521 rows x 28 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(train_sample.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_tree_analysis(X_train:pd.DataFrame, y_train:pd.DataFrame, X_test:pd.DataFrame, y_test:pd.DataFrame, criterion:str = 'gini', random_state:int = 1, num_crossval:int = 5, verbosity: int = 0):\n",
    "    assert criterion in ['entropy', 'gini'], 'invalid choice of criterion. Needs to be entropy or gini.'\n",
    "    full_tree = DecisionTreeClassifier(random_state=random_state)\n",
    "    full_tree.fit(X_train,y_train)\n",
    "    ccp_alphas = full_tree.cost_complexity_pruning_path(X_train,y_train)['ccp_alphas']\n",
    "    # ccp_alphas = [0.00001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    alpha_grid_search = GridSearchCV(\n",
    "                            estimator=DecisionTreeClassifier(random_state=random_state),\n",
    "                            scoring=make_scorer(accuracy_score),\n",
    "                            param_grid=ParameterGrid({\"ccp_alpha\": [[alpha] for alpha in ccp_alphas]}),\n",
    "                            n_jobs=-1,\n",
    "                            cv=num_crossval,\n",
    "                            verbose=verbosity\n",
    "                        )\n",
    "    alpha_grid_search.fit(X_train, y_train)\n",
    "    report = classification_report(y_test, alpha_grid_search.best_estimator_.predict(X_test))\n",
    "    print(report)\n",
    "    return alpha_grid_search, report\n",
    "    \n",
    "\n",
    "def tree_analysis(X: pd.core.frame.DataFrame, y: pd.core.frame.DataFrame, n_crossval: int = 10, criterion: str = 'entropy', scoring = 'balanced_accuracy', random_state: int = 1, ccp_alpha: float = 0, verbosity: bool = 0, n_jobs = -1):\n",
    "    assert criterion in ['entropy', 'gini'], 'invalid choice of criterion. Needs to be entropy or gini.'\n",
    "    classifier = DecisionTreeClassifier(criterion = criterion, random_state=random_state, ccp_alpha=ccp_alpha)\n",
    "    #y_pred = cross_val_predict(classifier, X = X, y = y, cv = n_crossval)\n",
    "    cross_val_scores = cross_val_score(classifier, X = X, y = y, cv = n_crossval, scoring = scoring, verbose = 1, n_jobs = -1)\n",
    "    #conf_matrix = confusion_matrix(y, y_pred)\n",
    "    return(np.mean(cross_val_scores), np.std(cross_val_scores))#, conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11203 candidates, totalling 56015 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "subset = numeric_data.sample(n=50000)\n",
    "train, test = train_test_split(subset)\n",
    "alpha_grid, report = improved_tree_analysis(train[input_features], train['OffAge'], test[input_features], test['OffAge'], verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(alpha_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying if training with dummies is feasible\n",
    "X = pd.get_dummies(X, columns=['County', 'State', 'Area', 'VicSex', 'VicRace', 'VicEthnic', 'VicCount', 'Weapon', 'Subcircum', 'Agency', 'Agentype', 'Circumstance', 'Homicide'])\n",
    "mean, std, conf_matrix = tree_analysis(X = X, y = y)\n",
    "# result: training this one decision tree takes 12 hours with dummy variables"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d06a35f6432bcea124c520d36814be75a6dd5ed4335e0c829924d510b7f0b7dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
